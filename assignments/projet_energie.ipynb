{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfdeIPitFSoK"
      },
      "source": [
        "# Projet: Pr√©diction de la demande √©nerg√©tique\n",
        "\n",
        "**IFT3395/IFT6390 - Fondements de l'apprentissage machine**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pierrelux/mlbook/blob/main/exercises/projet_energie.ipynb)\n",
        "\n",
        "**Comp√©tition Kaggle:** [Rejoindre la comp√©tition](https://www.kaggle.com/t/72daeb9bff104caf912f9a0b0f42eb5a)\n",
        "\n",
        "---\n",
        "\n",
        "## Contexte\n",
        "\n",
        "Hydro-Qu√©bec publie des donn√©es ouvertes sur la consommation √©lectrique de clients participant √† un programme de gestion de la demande. Ces donn√©es incluent la consommation horaire, les conditions m√©t√©orologiques, et des indicateurs d'√©v√©nements de pointe.\n",
        "\n",
        "Votre mission: construire un mod√®le de pr√©diction de la consommation √©nerg√©tique en utilisant **uniquement** les m√©thodes vues dans les chapitres 1 √† 5 du cours.\n",
        "\n",
        "## Objectifs d'apprentissage\n",
        "\n",
        "√Ä la fin de ce projet, vous serez en mesure de:\n",
        "\n",
        "1. Impl√©menter les moindres carr√©s ordinaires (OLS) √† partir de z√©ro\n",
        "2. Impl√©menter la r√©gression logistique avec descente de gradient\n",
        "3. Appliquer la r√©gularisation Ridge et interpr√©ter ses effets\n",
        "4. Construire un mod√®le √† deux √©tages: classification ‚Üí r√©gression\n",
        "5. Utiliser les probabilit√©s pr√©dites comme caract√©ristiques\n",
        "\n",
        "## Structure du projet\n",
        "\n",
        "| Partie | Contenu | Pond√©ration |\n",
        "|--------|---------|-------------|\n",
        "| 1 | Impl√©mentation OLS | 10% |\n",
        "| 2 | Impl√©mentation r√©gression logistique + DG | 15% |\n",
        "| 3 | Ing√©nierie des caract√©ristiques | 15% |\n",
        "| 4 | R√©gression Ridge | 15% |\n",
        "| 5 | Sous-t√¢che de classification | 15% |\n",
        "| 6 | Mod√®le combin√© | 10% |\n",
        "| 7 | Extension (choisir 1) | 10% |\n",
        "| Kaggle | Position au classement | 10% |\n",
        "\n",
        "**Note**: L'entrevue orale peut ajuster votre note de ¬±10%.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8nhZzcKFSoM"
      },
      "source": [
        "## Partie 0: Configuration et chargement des donn√©es\n",
        "\n",
        "Ex√©cutez cette cellule pour importer les biblioth√®ques et charger les donn√©es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5df3VW4FSoN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration des graphiques\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "print(\"Configuration termin√©e!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xyEYdnzFSoO"
      },
      "source": [
        "### Chargement des donn√©es\n",
        "\n",
        "Les donn√©es proviennent du jeu de donn√©es ouvert [consommation-clients-evenements-pointe](https://donnees.hydroquebec.com/explore/dataset/consommation-clients-evenements-pointe/) d'Hydro-Qu√©bec. Nous les chargeons directement depuis GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD6ahgCXFSoO"
      },
      "source": [
        "# URLs des donn√©es sur GitHub\n",
        "BASE_URL = \"https://raw.githubusercontent.com/pierrelux/mlbook/main/data/\"\n",
        "\n",
        "# Charger les donn√©es\n",
        "print(\"Chargement des donn√©es depuis GitHub...\")\n",
        "train = pd.read_csv(BASE_URL + \"energy_train.csv\", parse_dates=['horodatage_local'])\n",
        "\n",
        "# Pour l'√©valuation locale: test avec la cible (energie_kwh)\n",
        "test = pd.read_csv(BASE_URL + \"energy_test_avec_cible.csv\", parse_dates=['horodatage_local'])\n",
        "\n",
        "# Pour Kaggle: test sans la cible (pour g√©n√©rer les pr√©dictions)\n",
        "test_kaggle = pd.read_csv(BASE_URL + \"energy_test.csv\", parse_dates=['horodatage_local'])\n",
        "\n",
        "print(f\"Ensemble d'entra√Ænement: {len(train)} observations\")\n",
        "print(f\"Ensemble de test: {len(test)} observations\")\n",
        "print(f\"\\nP√©riode d'entra√Ænement: {train['horodatage_local'].min()} √† {train['horodatage_local'].max()}\")\n",
        "print(f\"P√©riode de test: {test['horodatage_local'].min()} √† {test['horodatage_local'].max()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6WUYyxNFSoP"
      },
      "source": [
        "# Aper√ßu des donn√©es\n",
        "print(\"Colonnes disponibles:\")\n",
        "print(train.columns.tolist())\n",
        "print(f\"\\nProportion √©v√©nements de pointe (train): {train['evenement_pointe'].mean():.1%}\")\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNC8G2JfFSoP"
      },
      "source": [
        "### Description des variables\n",
        "\n",
        "Les donn√©es contiennent des mesures m√©t√©orologiques et temporelles pour pr√©dire la consommation √©nerg√©tique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY_sNDOmFSoP"
      },
      "source": [
        "# Description des variables\n",
        "print(\"Variables m√©t√©orologiques:\")\n",
        "print(\"  - temperature_ext: Temp√©rature ext√©rieure moyenne (¬∞C)\")\n",
        "print(\"  - humidite: Humidit√© relative moyenne (%)\")\n",
        "print(\"  - vitesse_vent: Vitesse du vent moyenne (km/h)\")\n",
        "print(\"  - neige: Pr√©cipitations de neige moyennes\")\n",
        "print(\"  - irradiance_solaire: Irradiance solaire moyenne\")\n",
        "\n",
        "print(\"\\nVariables temporelles:\")\n",
        "print(\"  - heure, mois, jour, jour_semaine: Composantes temporelles\")\n",
        "print(\"  - heure_sin, heure_cos, mois_sin, mois_cos: Encodage cyclique\")\n",
        "print(\"  - est_weekend, est_ferie: Indicateurs binaires\")\n",
        "\n",
        "print(\"\\nAutres:\")\n",
        "print(\"  - evenement_pointe: Indicateur d'√©v√©nement de pointe (classification)\")\n",
        "print(\"  - energie_kwh: Variable cible (consommation en kWh)\")\n",
        "\n",
        "print(f\"\\nStatistiques de base:\")\n",
        "train[['temperature_ext', 'humidite', 'energie_kwh']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZGfmlCNFSoP"
      },
      "source": [
        "# IMPORTANT: Division temporelle d√©j√† effectu√©e\n",
        "# Les donn√©es de test couvrent la p√©riode √† partir du 1er f√©vrier 2024\n",
        "# NE PAS m√©langer les donn√©es - c'est une s√©rie temporelle!\n",
        "\n",
        "print(\"‚ö†Ô∏è  ATTENTION: Division temporelle\")\n",
        "print(\"Les ensembles train/test sont d√©j√† s√©par√©s chronologiquement.\")\n",
        "print(\"N'utilisez PAS de validation crois√©e al√©atoire (fuite d'information).\")\n",
        "print(\"\\nPour la validation, utilisez une division temporelle sur train:\")\n",
        "print(\"  - Ex: train[:6000] pour entra√Ænement, train[6000:] pour validation\")\n",
        "\n",
        "# Note: il y a un d√©calage de distribution entre train (hiver) et test (printemps/√©t√©)\n",
        "# C'est un d√©fi r√©aliste! Pensez √† utiliser des caract√©ristiques qui g√©n√©ralisent bien.\n",
        "print(\"\\nüìä D√©calage de distribution:\")\n",
        "print(f\"  Train: {train['energie_kwh'].mean():.1f} kWh (hiver)\")\n",
        "print(f\"  Test:  {test['energie_kwh'].mean():.1f} kWh (printemps/√©t√©)\")\n",
        "print(\"  ‚Üí Le mod√®le doit g√©n√©raliser √† travers les saisons!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXRaxwvhFSoQ"
      },
      "source": [
        "### Exploration visuelle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc2PqTKoFSoQ"
      },
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Consommation vs temp√©rature\n",
        "axes[0, 0].scatter(train['temperature_ext'], train['energie_kwh'], alpha=0.3, s=5)\n",
        "axes[0, 0].set_xlabel('Temp√©rature (¬∞C)')\n",
        "axes[0, 0].set_ylabel('√ânergie consomm√©e (kWh)')\n",
        "axes[0, 0].set_title('Consommation vs Temp√©rature')\n",
        "\n",
        "# Distribution de la consommation\n",
        "axes[0, 1].hist(train['energie_kwh'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_xlabel('√ânergie (kWh)')\n",
        "axes[0, 1].set_ylabel('Fr√©quence')\n",
        "axes[0, 1].set_title('Distribution de la consommation')\n",
        "\n",
        "# Profil horaire\n",
        "profil_horaire = train.groupby('heure')['energie_kwh'].mean()\n",
        "axes[1, 0].bar(profil_horaire.index, profil_horaire.values)\n",
        "axes[1, 0].set_xlabel('Heure')\n",
        "axes[1, 0].set_ylabel('√ânergie moyenne (kWh)')\n",
        "axes[1, 0].set_title('Profil de consommation horaire')\n",
        "\n",
        "# √âv√©nements de pointe par heure\n",
        "pointe_horaire = train.groupby('heure')['evenement_pointe'].mean()\n",
        "axes[1, 1].bar(pointe_horaire.index, pointe_horaire.values)\n",
        "axes[1, 1].set_xlabel('Heure')\n",
        "axes[1, 1].set_ylabel('Proportion √©v√©nements de pointe')\n",
        "axes[1, 1].set_title('Fr√©quence des √©v√©nements de pointe')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M82MJ5OFSoQ"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 1: Impl√©mentation OLS (10%)\n",
        "\n",
        "Avant d'utiliser scikit-learn, vous devez impl√©menter la solution analytique des moindres carr√©s ordinaires.\n",
        "\n",
        "**Rappel**: La solution OLS est donn√©e par:\n",
        "\n",
        "$$\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}$$\n",
        "\n",
        "Pour des raisons de stabilit√© num√©rique, pr√©f√©rez `np.linalg.solve` √† l'inversion directe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4J6rk2ZFSoQ"
      },
      "source": [
        "def ols_fit(X, y):\n",
        "    \"\"\"\n",
        "    Calcule les coefficients OLS.\n",
        "\n",
        "    Param√®tres:\n",
        "        X : ndarray de forme (n, p) - matrice de caract√©ristiques (SANS colonne de 1)\n",
        "        y : ndarray de forme (n,) - vecteur cible\n",
        "\n",
        "    Retourne:\n",
        "        beta : ndarray de forme (p+1,) - coefficients [intercept, coef1, coef2, ...]\n",
        "\n",
        "    Indice: Ajoutez une colonne de 1 √† X pour l'intercept.\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    # 1. Ajouter une colonne de 1 pour l'intercept\n",
        "    # 2. R√©soudre le syst√®me X^T X beta = X^T y\n",
        "    # 3. Retourner beta\n",
        "    pass\n",
        "\n",
        "\n",
        "def ols_predict(X, beta):\n",
        "    \"\"\"\n",
        "    Pr√©dit avec les coefficients OLS.\n",
        "\n",
        "    Param√®tres:\n",
        "        X : ndarray de forme (n, p) - caract√©ristiques (SANS colonne de 1)\n",
        "        beta : ndarray de forme (p+1,) - coefficients [intercept, coef1, ...]\n",
        "\n",
        "    Retourne:\n",
        "        y_pred : ndarray de forme (n,)\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5By6imqFSoQ"
      },
      "source": [
        "# Test de votre impl√©mentation\n",
        "# Caract√©ristiques simples pour commencer\n",
        "features_base = ['temperature_ext', 'humidite', 'vitesse_vent']\n",
        "\n",
        "X_train_base = train[features_base].values\n",
        "y_train = train['energie_kwh'].values\n",
        "X_test_base = test[features_base].values\n",
        "y_test = test['energie_kwh'].values\n",
        "\n",
        "# Votre impl√©mentation\n",
        "beta_ols = ols_fit(X_train_base, y_train)\n",
        "y_pred_ols = ols_predict(X_test_base, beta_ols)\n",
        "\n",
        "# Validation avec sklearn\n",
        "model_sklearn = LinearRegression()\n",
        "model_sklearn.fit(X_train_base, y_train)\n",
        "y_pred_sklearn = model_sklearn.predict(X_test_base)\n",
        "\n",
        "# Comparaison\n",
        "print(\"Comparaison OLS impl√©ment√© vs sklearn:\")\n",
        "print(f\"  Intercept - Vous: {beta_ols[0]:.4f}, sklearn: {model_sklearn.intercept_:.4f}\")\n",
        "print(f\"  Coefficients proches: {np.allclose(beta_ols[1:], model_sklearn.coef_, atol=1e-4)}\")\n",
        "print(f\"\\nR¬≤ sur test: {r2_score(y_test, y_pred_ols):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPpP1fSlFSoR"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 2: R√©gression logistique avec descente de gradient (15%)\n",
        "\n",
        "Impl√©mentez la r√©gression logistique pour la classification binaire.\n",
        "\n",
        "**Rappels**:\n",
        "- Fonction sigmo√Øde: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
        "- Perte d'entropie crois√©e: $L = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right]$\n",
        "- Gradient: $\\nabla L = \\frac{1}{n} \\mathbf{X}^\\top (\\sigma(\\mathbf{X}\\boldsymbol{\\beta}) - \\mathbf{y})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mt-TdDuFSoR"
      },
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Fonction sigmo√Øde.\n",
        "\n",
        "    Indice: Pour la stabilit√© num√©rique, clip z entre -500 et 500.\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    pass\n",
        "\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred_proba):\n",
        "    \"\"\"\n",
        "    Calcule la perte d'entropie crois√©e binaire.\n",
        "\n",
        "    Indice: Clip les probabilit√©s pour √©viter log(0).\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    pass\n",
        "\n",
        "\n",
        "def logistic_gradient(X, y, beta):\n",
        "    \"\"\"\n",
        "    Calcule le gradient de la perte d'entropie crois√©e.\n",
        "\n",
        "    Param√®tres:\n",
        "        X : ndarray (n, p+1) - caract√©ristiques AVEC colonne de 1\n",
        "        y : ndarray (n,) - √©tiquettes binaires\n",
        "        beta : ndarray (p+1,) - coefficients actuels\n",
        "\n",
        "    Retourne:\n",
        "        gradient : ndarray (p+1,)\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    pass\n",
        "\n",
        "\n",
        "def logistic_fit_gd(X, y, lr=0.1, n_iter=1000, verbose=False):\n",
        "    \"\"\"\n",
        "    Entra√Æne la r√©gression logistique par descente de gradient.\n",
        "\n",
        "    Param√®tres:\n",
        "        X : ndarray (n, p) - caract√©ristiques SANS colonne de 1\n",
        "        y : ndarray (n,) - √©tiquettes binaires (0 ou 1)\n",
        "        lr : float - taux d'apprentissage\n",
        "        n_iter : int - nombre d'it√©rations\n",
        "        verbose : bool - afficher la progression\n",
        "\n",
        "    Retourne:\n",
        "        beta : ndarray (p+1,) - coefficients [intercept, coef1, ...]\n",
        "        losses : list - historique des pertes\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    # 1. Ajouter colonne de 1 √† X\n",
        "    # 2. Initialiser beta √† z√©ro\n",
        "    # 3. Boucle de descente de gradient\n",
        "    # 4. Retourner beta et historique des pertes\n",
        "    pass\n",
        "\n",
        "\n",
        "def logistic_predict_proba(X, beta):\n",
        "    \"\"\"\n",
        "    Retourne les probabilit√©s P(Y=1|X).\n",
        "    \"\"\"\n",
        "    # VOTRE CODE ICI\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwHpazbTFSoR"
      },
      "source": [
        "# Test sur la pr√©diction des √©v√©nements de pointe\n",
        "# Caract√©ristiques pour classification\n",
        "features_clf = ['temperature_ext', 'heure_sin', 'heure_cos', 'est_weekend']\n",
        "\n",
        "X_train_clf = train[features_clf].values\n",
        "y_train_clf = train['evenement_pointe'].values\n",
        "X_test_clf = test[features_clf].values\n",
        "y_test_clf = test['evenement_pointe'].values\n",
        "\n",
        "# Normaliser (recommand√© pour la descente de gradient)\n",
        "scaler = StandardScaler()\n",
        "X_train_clf_scaled = scaler.fit_transform(X_train_clf)\n",
        "X_test_clf_scaled = scaler.transform(X_test_clf)\n",
        "\n",
        "# Entra√Æner votre mod√®le\n",
        "beta_log, losses = logistic_fit_gd(X_train_clf_scaled, y_train_clf, lr=0.1, n_iter=500, verbose=True)\n",
        "\n",
        "# Tracer la courbe de convergence\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(losses)\n",
        "plt.xlabel('It√©ration')\n",
        "plt.ylabel('Perte (entropie crois√©e)')\n",
        "plt.title('Convergence de la descente de gradient')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfgiHVRBFSoR"
      },
      "source": [
        "# √âvaluation\n",
        "proba_train = logistic_predict_proba(X_train_clf_scaled, beta_log)\n",
        "proba_test = logistic_predict_proba(X_test_clf_scaled, beta_log)\n",
        "\n",
        "y_pred_train = (proba_train >= 0.5).astype(int)\n",
        "y_pred_test = (proba_test >= 0.5).astype(int)\n",
        "\n",
        "print(\"√âvaluation de votre r√©gression logistique:\")\n",
        "print(f\"  Accuracy (train): {accuracy_score(y_train_clf, y_pred_train):.4f}\")\n",
        "print(f\"  Accuracy (test): {accuracy_score(y_test_clf, y_pred_test):.4f}\")\n",
        "print(f\"\\nRapport de classification (test):\")\n",
        "print(classification_report(y_test_clf, y_pred_test, target_names=['Normal', 'Pointe']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUYDKdxcFSoR"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 3: Ing√©nierie des caract√©ristiques (15%)\n",
        "\n",
        "**√Ä partir de maintenant, vous pouvez utiliser scikit-learn.**\n",
        "\n",
        "Cr√©ez des caract√©ristiques temporelles pour am√©liorer le mod√®le de r√©gression.\n",
        "\n",
        "### Caract√©ristiques √† impl√©menter:\n",
        "\n",
        "1. **Retards (lags)**: consommation aux heures pr√©c√©dentes\n",
        "2. **Statistiques glissantes**: moyenne mobile, √©cart-type mobile\n",
        "3. **Interactions**: temp√©rature √ó heure, etc.\n",
        "\n",
        "Impl√©mentez **au moins 3 nouvelles caract√©ristiques**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDXXzcYnFSoR"
      },
      "source": [
        "def creer_caracteristiques(df):\n",
        "    \"\"\"\n",
        "    Cr√©e des caract√©ristiques suppl√©mentaires.\n",
        "\n",
        "    VOUS DEVEZ IMPL√âMENTER AU MOINS 3 NOUVELLES CARACT√âRISTIQUES.\n",
        "\n",
        "    Id√©es:\n",
        "    - Retards: df['energie_kwh'].shift(1), shift(24)\n",
        "    - Moyennes mobiles: df['energie_kwh'].rolling(6).mean()\n",
        "    - Interactions: df['temperature_ext'] * df['heure_cos']\n",
        "    - Degr√©-jours de chauffage: np.maximum(18 - df['temperature_ext'], 0)\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # VOTRE CODE ICI\n",
        "    # Exemple:\n",
        "    # df['energie_lag1'] = df['energie_kwh'].shift(1)\n",
        "    # df['energie_rolling_6h'] = df['energie_kwh'].rolling(6).mean()\n",
        "    # df['temp_heure_interaction'] = df['temperature_ext'] * df['heure_cos']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Appliquer aux donn√©es\n",
        "train_eng = creer_caracteristiques(train)\n",
        "test_eng = creer_caracteristiques(test)\n",
        "\n",
        "# Supprimer les lignes avec NaN (dues aux retards)\n",
        "train_eng = train_eng.dropna()\n",
        "test_eng = test_eng.dropna()\n",
        "\n",
        "print(f\"Nouvelles colonnes: {[c for c in train_eng.columns if c not in train.columns]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWqgcpnhFSoR"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 4: R√©gression Ridge (15%)\n",
        "\n",
        "Avec plusieurs caract√©ristiques corr√©l√©es, la r√©gularisation devient utile.\n",
        "\n",
        "1. Entra√Ænez un mod√®le Ridge avec validation crois√©e pour choisir Œª\n",
        "2. Comparez les performances avec OLS\n",
        "3. Analysez comment les coefficients changent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qR7qhcAFSoR"
      },
      "source": [
        "# D√©finissez vos caract√©ristiques pour la r√©gression\n",
        "# MODIFIEZ CETTE LISTE selon vos caract√©ristiques cr√©√©es en Partie 3\n",
        "# IMPORTANT: clients_connectes est une variable tr√®s importante!\n",
        "features_reg = [\n",
        "    'temperature_ext', 'humidite', 'vitesse_vent', 'irradiance_solaire',\n",
        "    'heure_sin', 'heure_cos', 'mois_sin', 'mois_cos',\n",
        "    'jour_semaine_sin', 'jour_semaine_cos',\n",
        "    'est_weekend', 'est_ferie',\n",
        "    'clients_connectes',  # Ne pas oublier!\n",
        "    # Ajoutez vos caract√©ristiques ici\n",
        "]\n",
        "\n",
        "# V√©rifier que toutes les colonnes existent\n",
        "features_disponibles = [f for f in features_reg if f in train_eng.columns]\n",
        "print(f\"Caract√©ristiques utilis√©es: {len(features_disponibles)}\")\n",
        "\n",
        "X_train_reg = train_eng[features_disponibles].values\n",
        "y_train_reg = train_eng['energie_kwh'].values\n",
        "X_test_reg = test_eng[features_disponibles].values\n",
        "y_test_reg = test_eng['energie_kwh'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amaFyRs1FSoS"
      },
      "source": [
        "# Mod√®le OLS (baseline)\n",
        "model_ols = LinearRegression()\n",
        "model_ols.fit(X_train_reg, y_train_reg)\n",
        "y_pred_ols = model_ols.predict(X_test_reg)\n",
        "\n",
        "print(\"OLS (baseline):\")\n",
        "print(f\"  R¬≤ train: {model_ols.score(X_train_reg, y_train_reg):.4f}\")\n",
        "print(f\"  R¬≤ test:  {r2_score(y_test_reg, y_pred_ols):.4f}\")\n",
        "print(f\"  RMSE test: {np.sqrt(mean_squared_error(y_test_reg, y_pred_ols)):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eRbLoHpFSoS"
      },
      "source": [
        "# Mod√®le Ridge avec validation crois√©e\n",
        "# ATTENTION: Utilisez TimeSeriesSplit pour les donn√©es temporelles!\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "alphas = [0.01, 0.1, 1, 10, 100, 1000]\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "model_ridge = RidgeCV(alphas=alphas, cv=tscv)\n",
        "model_ridge.fit(X_train_reg, y_train_reg)\n",
        "y_pred_ridge = model_ridge.predict(X_test_reg)\n",
        "\n",
        "print(f\"\\nRidge (Œª={model_ridge.alpha_}):\")\n",
        "print(f\"  R¬≤ train: {model_ridge.score(X_train_reg, y_train_reg):.4f}\")\n",
        "print(f\"  R¬≤ test:  {r2_score(y_test_reg, y_pred_ridge):.4f}\")\n",
        "print(f\"  RMSE test: {np.sqrt(mean_squared_error(y_test_reg, y_pred_ridge)):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQor2TQeFSoS"
      },
      "source": [
        "# Comparaison des coefficients OLS vs Ridge\n",
        "coef_comparison = pd.DataFrame({\n",
        "    'Caract√©ristique': features_disponibles,\n",
        "    'OLS': model_ols.coef_,\n",
        "    'Ridge': model_ridge.coef_\n",
        "})\n",
        "coef_comparison['R√©duction (%)'] = 100 * (1 - np.abs(coef_comparison['Ridge']) / (np.abs(coef_comparison['OLS']) + 1e-8))\n",
        "coef_comparison = coef_comparison.sort_values('R√©duction (%)', ascending=False)\n",
        "\n",
        "print(\"\\nComparaison des coefficients (tri√©s par r√©duction):\")\n",
        "print(coef_comparison.to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWhAbD_EFSoS"
      },
      "source": [
        "**Questions pour l'entrevue orale**:\n",
        "- Pourquoi Ridge aide-t-il quand les caract√©ristiques sont corr√©l√©es?\n",
        "- Quelle caract√©ristique a √©t√© la plus r√©duite? Pourquoi?\n",
        "- Comment interpr√©ter Ridge comme estimation MAP?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcXM47UsFSoS"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 5: Sous-t√¢che de classification (15%)\n",
        "\n",
        "Entra√Ænez un classifieur pour pr√©dire les √©v√©nements de pointe, puis utilisez la probabilit√© pr√©dite comme caract√©ristique pour la r√©gression.\n",
        "\n",
        "**√âtapes**:\n",
        "1. Entra√Æner LogisticRegression sur `evenement_pointe`\n",
        "2. Extraire `P(pointe)` pour chaque observation\n",
        "3. Ajouter cette probabilit√© comme caract√©ristique pour Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egsebXprFSoS"
      },
      "source": [
        "# Caract√©ristiques pour la classification\n",
        "# Utilisez des caract√©ristiques qui ne \"trichent\" pas (pas de consommation pass√©e pour pr√©dire la pointe)\n",
        "features_pointe = ['temperature_ext', 'humidite', 'vitesse_vent', 'heure_sin', 'heure_cos', 'est_weekend', 'clients_connectes']\n",
        "\n",
        "X_train_pointe = train_eng[features_pointe].values\n",
        "y_train_pointe = train_eng['evenement_pointe'].values\n",
        "X_test_pointe = test_eng[features_pointe].values\n",
        "y_test_pointe = test_eng['evenement_pointe'].values\n",
        "\n",
        "# Entra√Æner le classifieur\n",
        "clf_pointe = LogisticRegression(max_iter=1000)\n",
        "clf_pointe.fit(X_train_pointe, y_train_pointe)\n",
        "\n",
        "# √âvaluation\n",
        "print(\"Classification des √©v√©nements de pointe:\")\n",
        "print(f\"  Accuracy (train): {clf_pointe.score(X_train_pointe, y_train_pointe):.4f}\")\n",
        "print(f\"  Accuracy (test): {clf_pointe.score(X_test_pointe, y_test_pointe):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN6FCtYxFSoS"
      },
      "source": [
        "# Extraire les probabilit√©s\n",
        "train_eng['P_pointe'] = clf_pointe.predict_proba(X_train_pointe)[:, 1]\n",
        "test_eng['P_pointe'] = clf_pointe.predict_proba(X_test_pointe)[:, 1]\n",
        "\n",
        "print(f\"Distribution de P(pointe):\")\n",
        "print(f\"  Train: moyenne={train_eng['P_pointe'].mean():.3f}, std={train_eng['P_pointe'].std():.3f}\")\n",
        "print(f\"  Test:  moyenne={test_eng['P_pointe'].mean():.3f}, std={test_eng['P_pointe'].std():.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIbjXWplFSoS"
      },
      "source": [
        "**Question pour l'entrevue**: Pourquoi utiliser P(pointe) au lieu d'un indicateur 0/1?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpYMI_DkFSoS"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 6: Mod√®le combin√© (10%)\n",
        "\n",
        "Assemblez le mod√®le final en ajoutant `P_pointe` comme caract√©ristique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7HIXiCCFSoS"
      },
      "source": [
        "# Caract√©ristiques finales (avec P_pointe)\n",
        "features_final = features_disponibles + ['P_pointe']\n",
        "\n",
        "X_train_final = train_eng[features_final].values\n",
        "y_train_final = train_eng['energie_kwh'].values\n",
        "X_test_final = test_eng[features_final].values\n",
        "y_test_final = test_eng['energie_kwh'].values\n",
        "\n",
        "# Mod√®le Ridge final\n",
        "model_final = RidgeCV(alphas=[0.1, 1, 10, 100], cv=TimeSeriesSplit(n_splits=5))\n",
        "model_final.fit(X_train_final, y_train_final)\n",
        "y_pred_final = model_final.predict(X_test_final)\n",
        "\n",
        "print(\"Mod√®le final (Ridge + P_pointe):\")\n",
        "print(f\"  Œª s√©lectionn√©: {model_final.alpha_}\")\n",
        "print(f\"  R¬≤ train: {model_final.score(X_train_final, y_train_final):.4f}\")\n",
        "print(f\"  R¬≤ test:  {r2_score(y_test_final, y_pred_final):.4f}\")\n",
        "print(f\"  RMSE test: {np.sqrt(mean_squared_error(y_test_final, y_pred_final)):.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWWBdLQfFSoS"
      },
      "source": [
        "# Comparaison: avec vs sans P_pointe\n",
        "print(\"\\n=== R√©capitulatif ===\")\n",
        "print(f\"OLS baseline:     R¬≤ = {r2_score(y_test_reg, y_pred_ols):.4f}\")\n",
        "print(f\"Ridge:            R¬≤ = {r2_score(y_test_reg, y_pred_ridge):.4f}\")\n",
        "print(f\"Ridge + P_pointe: R¬≤ = {r2_score(y_test_final, y_pred_final):.4f}\")\n",
        "print(f\"\\nAm√©lioration due √† P_pointe: +{100*(r2_score(y_test_final, y_pred_final) - r2_score(y_test_reg, y_pred_ridge)):.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSRCzeCFSoS"
      },
      "source": [
        "# Visualisation des r√©sidus\n",
        "residus = y_test_final - y_pred_final\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Histogramme des r√©sidus\n",
        "axes[0].hist(residus, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(0, color='red', linestyle='--', label='Z√©ro')\n",
        "axes[0].set_xlabel('R√©sidu')\n",
        "axes[0].set_ylabel('Fr√©quence')\n",
        "axes[0].set_title('Distribution des r√©sidus')\n",
        "axes[0].legend()\n",
        "\n",
        "# Pr√©dictions vs r√©el\n",
        "axes[1].scatter(y_test_final, y_pred_final, alpha=0.3, s=5)\n",
        "axes[1].plot([y_test_final.min(), y_test_final.max()],\n",
        "             [y_test_final.min(), y_test_final.max()], 'r--', label='Parfait')\n",
        "axes[1].set_xlabel('√ânergie r√©elle (kWh)')\n",
        "axes[1].set_ylabel('√ânergie pr√©dite (kWh)')\n",
        "axes[1].set_title('Pr√©dictions vs R√©el')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nhm_kICFSoT"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 7: Extension (10%) - Choisir UNE option\n",
        "\n",
        "### Option A: Donn√©es m√©t√©orologiques externes\n",
        "Utilisez la biblioth√®que `meteostat` pour ajouter des donn√©es m√©t√©o suppl√©mentaires (ex: pression atmosph√©rique, point de ros√©e).\n",
        "\n",
        "### Option B: Classification multiclasse\n",
        "Au lieu de binaire (pointe/normal), cr√©ez 3+ classes de consommation (faible/moyenne/√©lev√©e) et utilisez softmax.\n",
        "\n",
        "### Option C: Analyse d'erreur approfondie\n",
        "Identifiez quand le mod√®le fait le plus d'erreurs et proposez des am√©liorations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PDcKp5NFSoT"
      },
      "source": [
        "# VOTRE EXTENSION ICI\n",
        "# Indiquez quelle option vous avez choisie et pourquoi.\n",
        "\n",
        "# Option choisie: ___\n",
        "# Justification: ___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XixYflntFSoT"
      },
      "source": [
        "---\n",
        "\n",
        "## Soumission Kaggle\n",
        "\n",
        "G√©n√©rez votre fichier de soumission pour la comp√©tition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6E4VzbZFSoT"
      },
      "source": [
        "# G√©n√©rer les pr√©dictions pour Kaggle (sur test_kaggle, sans la cible)\n",
        "# Note: utilisez votre meilleur mod√®le pour faire ces pr√©dictions\n",
        "# Exemple avec le mod√®le final:\n",
        "# X_kaggle = test_kaggle[features_final].values\n",
        "# y_pred_kaggle = votre_modele.predict(X_kaggle)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': range(len(test_kaggle)),\n",
        "    'energie_kwh': y_pred_final  # Remplacez par vos pr√©dictions sur test_kaggle\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(f\"Fichier de soumission cr√©√©: submission.csv ({len(submission)} lignes)\")\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IsqQ04GFSoT"
      },
      "source": [
        "---\n",
        "\n",
        "## Questions de pr√©paration pour l'entrevue orale\n",
        "\n",
        "Pr√©parez-vous √† r√©pondre √† ces questions:\n",
        "\n",
        "### Fondamentaux\n",
        "1. D√©rivez la solution OLS sur le tableau.\n",
        "2. Pourquoi avez-vous utilis√© une division temporelle et non al√©atoire?\n",
        "3. Que voyez-vous dans vos r√©sidus?\n",
        "\n",
        "### R√©gularisation\n",
        "4. Pourquoi Ridge aide-t-il avec des caract√©ristiques corr√©l√©es?\n",
        "5. Comment avez-vous choisi Œª?\n",
        "6. Quel coefficient a √©t√© le plus r√©duit? Pourquoi?\n",
        "\n",
        "### Classification\n",
        "7. Quelle cible binaire avez-vous choisie? Justifiez.\n",
        "8. Votre classifieur donne P=0.7. Qu'est-ce que cela signifie?\n",
        "9. Pourquoi utiliser P(pointe) plut√¥t qu'un indicateur 0/1?\n",
        "\n",
        "### Th√©orie probabiliste\n",
        "10. Expliquez Ridge comme estimation MAP.\n",
        "11. Pourquoi la r√©gression logistique minimise-t-elle l'entropie crois√©e?\n",
        "\n",
        "### Synth√®se\n",
        "12. Parcourez votre mod√®le complet √©tape par √©tape.\n",
        "13. Quelle am√©lioration de R¬≤ √©tait la plus importante?\n",
        "14. Modifiez ce seuil en direct - que pr√©disez-vous?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}